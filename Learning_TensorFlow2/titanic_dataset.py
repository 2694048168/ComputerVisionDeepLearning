#!/usr/bin/env python3
# encoding: utf-8

"""
@Function: TensorFlow2 for Titanic dataset
@Brief: titanic 数据集的目标是根据乘客信息预测他们在 Titanic 号撞击冰山沉没后能否生存
@Dataset: https://gitee.com/Python_Ai_Road/eat_tensorflow2_in_30_days/tree/master/data/titanic
@Dataset: https://github.com/lyhue1991/eat_tensorflow2_in_30_days/tree/master/data/titanic
@Python Version: 3.8.12
@Author: Wei Li
@Date: 2022-03-12
"""

# Overview of the source code
""" -------------------------------------------------
Stage 1. Dataset Processing
Stage 2. Define Models
Stage 3. Training Models
Stage 4. Evaluate Models
Stage 5. Using Modles
Stage 6. Saving Models and Load Models
-------------------------------------------------"""

import os
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf

# -------------------------------------------------
# Dataset Processing
# -------------------------------------------------

# 结构化数据一般会使用 Pandas 中的 DataFrame 进行预处理
train_csv = r"./titanic/train.csv"
test_csv = r"./titanic/test.csv"

df_train_data = pd.read_csv(train_csv)
df_test_data = pd.read_csv(test_csv)

# print(f"train data shape = {df_train_data.shape}")
# print(f"test data shape = {df_test_data.shape}")
# print(f"train data information:\n {df_train_data.head()}")
# print(f"test data information:\n {df_test_data.head()}")

# 字段说明：
# ------------------------------------------------------------------------
# Survived: 0代表死亡，1代表存活【y标签】
# Pclass: 乘客所持票类，有三种值(1,2,3) 【转换成onehot编码】
# Name: 乘客姓名 【舍去】
# Sex: 乘客性别 【转换成bool特征】
# Age: 乘客年龄(有缺失) 【数值特征，添加“年龄是否缺失”作为辅助特征】
# SibSp: 乘客兄弟姐妹/配偶的个数(整数值) 【数值特征】
# Parch: 乘客父母/孩子的个数(整数值)【数值特征】
# Ticket: 票号(字符串)【舍去】
# Fare: 乘客所持票的价格(浮点数，0-500不等) 【数值特征】
# Cabin: 乘客所在船舱(有缺失) 【添加“所在船舱是否缺失”作为辅助特征】
# Embarked: 乘客登船港口:S、C、Q(有缺失)【转换成onehot编码，四维度 S,C,Q,nan】
# ------------------------------------------------------------------------

# 利用 Pandas 的数据可视化功能可以简单地进行探索性数据分析 EDA(Exploratory Data Analysis)
img2save_folder = r"./images"
os.makedirs(img2save_folder, exist_ok=True)

# Step 1 for label distribution
ax_label = df_train_data["Survived"].value_counts().plot(kind="bar", figsize=(8, 6), fontsize=15, rot=0)
ax_label.set_ylabel("Counts", fontsize=15)
ax_label.set_xlabel("Survived", fontsize=15)
# plt.show()
# plt.savefig(os.path.join(img2save_folder, "label_dist.png"), dpi=120)
plt.close()

# Step 2 for age distribution
ax_age = df_train_data["Age"].plot(kind="hist", bins=20, color="purple", figsize=(8, 6), fontsize=15)
ax_age.set_ylabel("Frequency", fontsize=15)
ax_age.set_xlabel("Age", fontsize=15)
# plt.show()
# plt.savefig(os.path.join(img2save_folder, "age_dist.png"), dpi=120)
plt.close()

# Step 3 for correlation of age and label
ax_corr_age_label = df_train_data.query("Survived==0")["Age"].plot(kind="density", figsize=(8, 6), fontsize=15)
df_train_data.query("Survived==1")["Age"].plot(kind="density", figsize=(8, 6), fontsize=15)
ax_corr_age_label.legend(["Survived==0", "Survived==0"], fontsize=12)
ax_corr_age_label.set_ylabel("Density", fontsize=15)
ax_corr_age_label.set_xlabel("Age", fontsize=15)
# plt.show()
# plt.savefig(os.path.join(img2save_folder, "corr_age_label.png"), dpi=120)
plt.close()


# data processing for Titanic Dataset
def preprocessing(df_data):
    df_result= pd.DataFrame()

    # Pclass term
    df_Pclass = pd.get_dummies(df_data['Pclass'])
    df_Pclass.columns = ['Pclass_' +str(x) for x in df_Pclass.columns]
    df_result = pd.concat([df_result, df_Pclass], axis=1)

    # Sex term
    df_Sex = pd.get_dummies(df_data['Sex'])
    df_result = pd.concat([df_result, df_Sex], axis=1)

    # Age term
    df_result['Age'] = df_data['Age'].fillna(0)
    df_result['Age_null'] = pd.isna(df_data['Age']).astype('int32')

    # SibSp, Parch, Fare terms
    df_result['SibSp'] = df_data['SibSp']
    df_result['Parch'] = df_data['Parch']
    df_result['Fare'] = df_data['Fare']

    # Carbin term
    df_result['Cabin_null'] =  pd.isna(df_data['Cabin']).astype('int32')

    # Embarked term
    df_Embarked = pd.get_dummies(df_data['Embarked'], dummy_na=True)
    df_Embarked.columns = ['Embarked_' + str(x) for x in df_Embarked.columns]
    df_result = pd.concat([df_result, df_Embarked], axis=1)

    return df_result

x_train = preprocessing(df_train_data)
y_train = df_train_data['Survived'].values

x_test = preprocessing(df_test_data)
y_test = df_test_data['Survived'].values

# print(f"x_train shape = {x_train.shape}")
# print(f"y_train shape = {y_train.shape}")
# print(f"x_test shape = {x_test.shape}")
# print(f"y_test shape = {y_test.shape}")


# ---------------------------------------
# Define the Model for Titanic Dataset
# ---------------------------------------
# Resets all state generated by Keras
tf.keras.backend.clear_session()

# TensorFlow2 way-3, Inherit Model class to Model
# -------------------------------------------------
# class CustomModel(tf.keras.Model):
#     def __init__(self):
#         super().__init__()

#         self.linear_1 = tf.keras.layers.Dense(20, activation="relu")
#         self.linear_2 = tf.keras.layers.Dense(15, activation="relu")
#         self.linear_3 = tf.keras.layers.Dense(1, activation="sigmoid")

#     def call(self, input):
#         x = self.linear_1(input)
#         x = self.linear_2(x)
#         x = self.linear_3(x)

#         return x

# model = CustomModel()
# -------------------------------------------------

# TensorFlow2 way-2, Functional API to Model
# -------------------------------------------------
# def functional_model():
#     input = tf.keras.Input(shape=(15, ))
#     x = tf.keras.layers.Dense(20, activation="relu")(input)
#     x = tf.keras.layers.Dense(15, activation="relu")(x)
#     x = tf.keras.layers.Dense(1, activation="sigmoid")(x)

#     model = tf.keras.Model(inputs=input, outputs=x)

#     return model

# model = functional_model()
# -------------------------------------------------

# TensorFlow2 way-1, Sequential container to Model
# -------------------------------------------------
model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Dense(20, activation="relu", input_shape=(15, )))
model.add(tf.keras.layers.Dense(15, activation="relu"))
model.add(tf.keras.layers.Dense(1, activation="sigmoid"))

# model = tf.keras.Sequential(
#     [
#         tf.keras.layers.Dense(20, activation="relu", input_shape=(15, )),
#         tf.keras.layers.Dense(15, activation="relu"),
#         tf.keras.layers.Dense(1, activation="sigmoid"),
#     ]
# )
# -------------------------------------------------

# model.summary()

# --------------------------------------------
# Training Model with TensorFlow2
# --------------------------------------------
# Tensorflow2 training way-3 custom-self loop training method
# Tensorflow2 training way-2 built-in train_on_batch method
# Tensorflow2 training way-1 built-in fit method

# Configure the training phase
model.compile(optimizer="adam",
    loss="binary_crossentropy",
    metrics=["AUC"])

# Training the model to fit data
history = model.fit(x_train, y_train,
    batch_size=64,
    epochs=6,
    validation_split=0.2)


# ------------------------------------------------- 
# Evaluate and Analyze the model
# ------------------------------------------------- 

# Step 1. evaluate the model on trainset and valset
def plot_metric(history, metric):
    train_metrics = history.history[metric]
    val_metrics = history.history["val_" + metric]
    epochs = range(1, len(train_metrics) + 1)
    
    plt.plot(epochs, train_metrics, "bo--")
    plt.plot(epochs, val_metrics, "ro-")
    plt.title("Training and validation " + metric)
    plt.xlabel("Epochs")
    plt.xlabel(metric)
    plt.legend(["train_" + metric, "val_" + metric])
    # plt.show()
    plt.savefig(os.path.join(img2save_folder, f"train_val_{metric}.png"), dpi=120)
    plt.close()

# plot_metric(history, "loss")
# plot_metric(history, "auc")

# Step 2. evaluate the model on testset
# print("---------------- Evaluate Model on Test Set ----------------")
# result = model.evaluate(x=x_test, y=y_test)
# print(f"the return of Model is : {type(result)}")
# print(f"the loss of Test for Model is : {result[0]}")
# print(f"the AUC of Test for Model is : {result[1]}")


# -------------------------------------
# How to use the trained Model
# -------------------------------------
print("---------------- Using Model to predict ----------------")
# predict_probability = model.predict(x_test[0:10])
predict_probability = model(tf.constant(x_test[0:10].values, dtype=tf.float32)) # or == call method
print(f"The return type of prediction method is : {type(predict_probability)}")
print(f"The return value of prediction method is \n : {predict_probability}")

# [Error]: Tensorflow 2.8.0 API has no attribute 'predict_classes' for Sequential Object ???
# predict_calsses = model.predict_classes(x_test[0:10])
# print(f"The return value of prediction method is : {predict_calsses}")

# -----------------------------------
# Saving Model with TensorFlow2
# -----------------------------------
path2models = r"./Models/Titanic"
os.makedirs(path2models, exist_ok=True)

# TensorFlow2 save model way-1 keras .h5 format to just support python env.
# TensorFlow2 save model way-2 TensorFlow format to support cross-platform
# TensorFlow2 save model way-3 TensorFlow format with checkpoint using callback

# ---- Step 1. save keras format .h5
# model.save(os.path.join(path2models, "keras_model.h5"))

# delete current model
# del model

# identical to the previous one
# model = tf.keras.models.Sequential()
# model.add(tf.keras.layers.Dense(20, activation="relu", input_shape=(15, )))
# model.add(tf.keras.layers.Dense(15, activation="relu"))
# model.add(tf.keras.layers.Dense(1, activation="sigmoid"))

# # [Error]: Tensorflow 2.8.0 API has no attribute 'load_model' for Sequential Object ???
# model = model.load_model(os.path.join(path2models, "keras_model.h5"))
# print(model.evaluate(x_test, y_test))


# ---- Step 2. save model with model arch. and model weight
# json_str = model.to_json()
# model.save_weights(os.path.join(path2models, "keras_model_weight.h5"))

# model_json = model.model_from_json(json_str)
# model_json.compile(optimizer="adam",
#     loss="binary_crossentropy",
#     metrics=["AUC"])

# model_json.load_weights(os.path.join(path2models, "keras_model_weight.h5"))
# print(model_json.evaluate(x_test, y_test))


# ---- Step 3. save model with TensorFlow original format
# model.save_weights(os.path.join(path2models, "tf_model_weight.ckpt"), save_foramt="tf")

model.save(os.path.join(path2models, "tf_model_save"), save_format="tf")
model_loaded = tf.keras.models.load_model(os.path.join(path2models, "tf_model_save"))
print(model_loaded.evaluate(x_test, y_test))